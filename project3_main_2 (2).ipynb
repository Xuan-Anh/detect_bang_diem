{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZW3FU-zA5ib",
        "outputId": "8b27395b-8e49-453b-d3cd-6e0eddd5411d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGzlSF1ND1DS",
        "outputId": "9a8d7c64-8e3e-4a91-ae6e-d6781dd272de"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIp68acxD1c7"
      },
      "outputs": [],
      "source": [
        "# % cd /content/drive/MyDrive/xa/code_xa/project3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9rMaJX57iMQ"
      },
      "outputs": [],
      "source": [
        "# %%capture \n",
        "# ! pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUBzC-Eq_tPP"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! pip install icecream\n",
        "from icecream import ic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4uD-qvVXk09"
      },
      "outputs": [],
      "source": [
        "# ! git clone https://github.com/ultralytics/yolov5.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sktxk4RhwWHU"
      },
      "outputs": [],
      "source": [
        "# /content/drive/MyDrive/xa/code_xa/project3/yolov5/train.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLCwN2jHrpzs"
      },
      "source": [
        "Train Yolov5 in custom data\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpArDTdcwY-L",
        "outputId": "152e8d19-1c83-4c1b-9bc0-5c78686dd82f"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/xa/code_xa/project3\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tHk5J2RtwKi"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! pip install -r /content/drive/MyDrive/xa/code_xa/project3/yolov5/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXIaqEZpoj5m"
      },
      "outputs": [],
      "source": [
        "# !python yolov5/train.py --img 640 --batch 70 --epochs 100  --data yolov5/data/table_sami.yaml --weights yolov5s.pt --cache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVbW7OGQ1p2X"
      },
      "source": [
        "weight lưu ở exp29"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1FXK1bREqQs",
        "outputId": "13abf481-e657-419e-e2ef-1112e331e6c6"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/xa/code_xa/project3/yolov5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "silUayU9CtgM"
      },
      "outputs": [],
      "source": [
        "# !python detect.py --weights /content/drive/MyDrive/xa/code_xa/project3/yolov5/runs/train/exp21/weights/last.pt --source ../project3_data_test --save-txt  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2e-hY-IkIhdr"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageEnhance\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAkbPoRVI4Gu"
      },
      "outputs": [],
      "source": [
        "def plot(img):\n",
        "  plt.figure(figsize=(15,10))\n",
        "  plt.imshow(img, cmap = \"gray\")\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kPcTa94amJD"
      },
      "source": [
        "# Xoay ảnh "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "id": "uZmYyyafam-7",
        "outputId": "1203efab-0241-410a-8b17-d71c1477a9e6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from skimage.transform import hough_line, hough_line_peaks\n",
        "from skimage.transform import rotate\n",
        "from skimage.feature import canny\n",
        "from skimage.io import imread\n",
        "from skimage.color import rgb2gray\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import mode\n",
        "\n",
        "image = rgb2gray(imread(\"/content/drive/MyDrive/xa/code_xa/project3/project3_data_test/Copy of BĐ ĐS-MI1112 - GK2020.1-63.jpg\"))\n",
        "\n",
        "edges = canny(image)\n",
        "# Classic straight-line Hough transform\n",
        "tested_angles = np.deg2rad(np.arange(0.1, 180.0))\n",
        "h, theta, d = hough_line(edges, theta=tested_angles)\n",
        "\n",
        "# Generating figure 1\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 16))\n",
        "ax = axes.ravel()\n",
        "\n",
        "ax[0].imshow(image, cmap=\"gray\")\n",
        "ax[0].set_title('Input image')\n",
        "ax[0].set_axis_off()\n",
        "\n",
        "ax[1].imshow(edges, cmap=\"gray\")\n",
        "origin = np.array((0, image.shape[1]))\n",
        "\n",
        "for _, angle, dist in zip(*hough_line_peaks(h, theta, d)):\n",
        "    y0, y1 = (dist - origin * np.cos(angle)) / np.sin(angle)\n",
        "    ax[1].plot(origin, (y0, y1), '-r')\n",
        "    \n",
        "ax[1].set_xlim(origin)\n",
        "ax[1].set_ylim((edges.shape[0], 0))\n",
        "ax[1].set_axis_off()\n",
        "ax[1].set_title('Detected lines')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 804
        },
        "id": "zbX6tkNccsFx",
        "outputId": "3087be96-407c-4ef4-cbac-1e62d08a7431"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "def skew_angle_hough_transform(image):\n",
        "    # convert to edges\n",
        "    edges = canny(image)\n",
        "    # Classic straight-line Hough transform between 0.1 - 180 degrees.\n",
        "    tested_angles = np.deg2rad(np.arange(0.1, 180.0))\n",
        "    h, theta, d = hough_line(edges, theta=tested_angles)\n",
        "    \n",
        "    # find line peaks and angles\n",
        "    accum, angles, dists = hough_line_peaks(h, theta, d)\n",
        "    \n",
        "    # round the angles to 2 decimal places and find the most common angle.\n",
        "    most_common_angle = mode(np.around(angles, decimals=2))[0]\n",
        "    \n",
        "    # convert the angle to degree for rotation.\n",
        "    skew_angle = np.rad2deg(most_common_angle - np.pi/2)\n",
        "    print(skew_angle)\n",
        "    return skew_angle\n",
        "    \n",
        "fig, ax = plt.subplots(ncols=2, figsize=(20,20))\n",
        "ax[0].imshow(image, cmap=\"gray\")\n",
        "rotated_image = rotate(image, skew_angle_hough_transform(image),  cval=1)\n",
        "ax[1].imshow(rotated_image, cmap = \"gray\")\n",
        "print(type(rotated_image))\n",
        "from PIL import Image\n",
        "I = rotated_image\n",
        "I8 = (((I - I.min()) / (I.max() - I.min())) * 255.9).astype(np.uint8)\n",
        "\n",
        "img = Image.fromarray(I8)\n",
        "img.save(\"/content/drive/MyDrive/xa/code_xa/project3/project3_data_rotated/Copy of BĐ ĐS-MI1112 - GK2020.1-63.jpg\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpPPMrXib9Wj"
      },
      "source": [
        "# Sử dụng yoloV5 để xác định bảng điểm "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvekzu6XcBjX"
      },
      "outputs": [],
      "source": [
        "# !python detect.py --weights /content/drive/MyDrive/xa/code_xa/project3/yolov5/runs/train/exp21/weights/last.pt --source ../project3_data_rotated --save-txt  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N76xe7L1veka",
        "outputId": "71bca0be-b6fa-4af7-96d9-18f5ecb03164"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/xa/code_xa/project3/yolov5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2G2Y2ApwKH5",
        "outputId": "20efe274-bb61-4bcb-abc4-346421f5b4f9"
      },
      "outputs": [],
      "source": [
        "\n",
        "import argparse\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "from models.common import DetectMultiBackend\n",
        "from utils.datasets import IMG_FORMATS, VID_FORMATS, LoadImages, LoadStreams\n",
        "from utils.general import (LOGGER, check_file, check_img_size, check_imshow, check_requirements, colorstr,\n",
        "                           increment_path, non_max_suppression, print_args, scale_coords, strip_optimizer, xyxy2xywh)\n",
        "from utils.plots import Annotator, colors, save_one_box\n",
        "from utils.torch_utils import select_device, time_sync\n",
        "\n",
        "ROOT = \"/content/drive/MyDrive/xa/code_xa/project3/yolov5\"\n",
        "if str(ROOT) not in sys.path:\n",
        "    sys.path.append(str(ROOT))  # add ROOT to PATH\n",
        "ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\n",
        "@torch.no_grad()\n",
        "def detect_by_yolov5(weights=ROOT / 'yolov5s.pt',  # model.pt path(s)\n",
        "        source=ROOT / 'data/images',  # file/dir/URL/glob, 0 for webcam\n",
        "        imgsz=640,  # inference size (pixels)\n",
        "        conf_thres=0.25,  # confidence threshold\n",
        "        iou_thres=0.45,  # NMS IOU threshold\n",
        "        max_det=1000,  # maximum detections per image\n",
        "        device='',  # cuda device, i.e. 0 or 0,1,2,3 or cpu\n",
        "        view_img=False,  # show results\n",
        "        save_txt=False,  # save results to *.txt\n",
        "        save_conf=False,  # save confidences in --save-txt labels\n",
        "        save_crop=False,  # save cropped prediction boxes\n",
        "        nosave=False,  # do not save images/videos\n",
        "        classes=None,  # filter by class: --class 0, or --class 0 2 3\n",
        "        agnostic_nms=False,  # class-agnostic NMS\n",
        "        augment=False,  # augmented inference\n",
        "        visualize=False,  # visualize features\n",
        "        update=False,  # update all models\n",
        "        project=ROOT / 'runs/detect',  # save results to project/name\n",
        "        name='exp',  # save results to project/name\n",
        "        exist_ok=False,  # existing project/name ok, do not increment\n",
        "        line_thickness=3,  # bounding box thickness (pixels)\n",
        "        hide_labels=False,  # hide labels\n",
        "        hide_conf=False,  # hide confidences\n",
        "        half=False,  # use FP16 half-precision inference\n",
        "        dnn=False,  # use OpenCV DNN for ONNX inference\n",
        "        ):\n",
        "    all_detect = []\n",
        "    source = str(source)\n",
        "    save_img = not nosave and not source.endswith('.txt')  # save inference images\n",
        "    is_file = Path(source).suffix[1:] in (IMG_FORMATS + VID_FORMATS)\n",
        "    is_url = source.lower().startswith(('rtsp://', 'rtmp://', 'http://', 'https://'))\n",
        "    webcam = source.isnumeric() or source.endswith('.txt') or (is_url and not is_file)\n",
        "    if is_url and is_file:\n",
        "        source = check_file(source)  # download\n",
        "\n",
        "    # Directories\n",
        "    save_dir = increment_path(Path(project) / name, exist_ok=exist_ok)  # increment run\n",
        "    (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n",
        "\n",
        "    # Load model\n",
        "    device = select_device(device)\n",
        "    model = DetectMultiBackend(weights, device=device, dnn=dnn)\n",
        "    stride, names, pt, jit, onnx = model.stride, model.names, model.pt, model.jit, model.onnx\n",
        "    imgsz = check_img_size(imgsz, s=stride)  # check image size\n",
        "\n",
        "    # Half\n",
        "    half &= pt and device.type != 'cpu'  # half precision only supported by PyTorch on CUDA\n",
        "    if pt:\n",
        "        model.model.half() if half else model.model.float()\n",
        "\n",
        "    # Dataloader\n",
        "    if webcam:\n",
        "        view_img = check_imshow()\n",
        "        cudnn.benchmark = True  # set True to speed up constant image size inference\n",
        "        dataset = LoadStreams(source, img_size=imgsz, stride=stride, auto=pt and not jit)\n",
        "        bs = len(dataset)  # batch_size\n",
        "    else:\n",
        "        dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt and not jit)\n",
        "        bs = 1  # batch_size\n",
        "    vid_path, vid_writer = [None] * bs, [None] * bs\n",
        "\n",
        "    # Run inference\n",
        "    if pt and device.type != 'cpu':\n",
        "        model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.model.parameters())))  # warmup\n",
        "    dt, seen = [0.0, 0.0, 0.0], 0\n",
        "    for path, im, im0s, vid_cap, s in dataset:\n",
        "        t1 = time_sync()\n",
        "        im = torch.from_numpy(im).to(device)\n",
        "        im = im.half() if half else im.float()  # uint8 to fp16/32\n",
        "        im /= 255  # 0 - 255 to 0.0 - 1.0\n",
        "        if len(im.shape) == 3:\n",
        "            im = im[None]  # expand for batch dim\n",
        "        t2 = time_sync()\n",
        "        dt[0] += t2 - t1\n",
        "\n",
        "        # Inference\n",
        "        visualize = increment_path(save_dir / Path(path).stem, mkdir=True) if visualize else False\n",
        "        pred = model(im, augment=augment, visualize=visualize)\n",
        "        t3 = time_sync()\n",
        "        dt[1] += t3 - t2\n",
        "\n",
        "        # NMS\n",
        "        pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det)\n",
        "        dt[2] += time_sync() - t3\n",
        "        \n",
        "\n",
        "\n",
        "        for i, det in enumerate(pred):  # per image\n",
        "            seen += 1\n",
        "            if webcam:  # batch_size >= 1\n",
        "                p, im0, frame = path[i], im0s[i].copy(), dataset.count\n",
        "                s += f'{i}: '\n",
        "            else:\n",
        "                p, im0, frame = path, im0s.copy(), getattr(dataset, 'frame', 0)\n",
        "\n",
        "            p = Path(p)  # to Path\n",
        "            save_path = str(save_dir / p.name)  # im.jpg\n",
        "            txt_path = str(save_dir / 'labels' / p.stem) + ('' if dataset.mode == 'image' else f'_{frame}')  # im.txt\n",
        "            s += '%gx%g ' % im.shape[2:]  # print string\n",
        "            gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n",
        "            imc = im0.copy() if save_crop else im0  # for save_crop\n",
        "            annotator = Annotator(im0, line_width=line_thickness, example=str(names))\n",
        "            if len(det):\n",
        "                # Rescale boxes from img_size to im0 size\n",
        "                det[:, :4] = scale_coords(im.shape[2:], det[:, :4], im0.shape).round()\n",
        "\n",
        "                # Print results\n",
        "                for c in det[:, -1].unique():\n",
        "                    n = (det[:, -1] == c).sum()  # detections per class\n",
        "                    s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n",
        "\n",
        "                # Write results\n",
        "                for *xyxy, conf, cls in reversed(det):\n",
        "                     # Write to file\n",
        "                        xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n",
        "                        ic(xywh)\n",
        "                        \n",
        "                        line = (cls, *xywh, conf) if save_conf else (cls, *xywh)  # label format\n",
        "                        detected =  (('%g ' * len(line)).rstrip() % line + '\\n')\n",
        "                        all_detect.append(detected)\n",
        "    return all_detect\n",
        "# detect_by_yolov5(weights = weight_yolov5, device = \"cuda\", source = path )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IacN2je1wnHs"
      },
      "source": [
        "## Hiện ảnh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "iABk4pLQE3PM",
        "outputId": "674fe7c8-c227-41f1-f013-39e7fccf361b"
      },
      "outputs": [],
      "source": [
        "import PIL \n",
        "path_img = \"/content/drive/MyDrive/xa/code_xa/project3/yolov5/runs/detect/exp10/Copy of BĐ ĐS-MI1112 - GK2020.1-63.jpg\"\n",
        "image_test = PIL.Image.open(path_img)\n",
        "# image to open\n",
        "image_width, image_height = image_test.size\n",
        "image_test = cv2.imread(path_img)\n",
        "plot(image_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e80rGVxrbvcA"
      },
      "source": [
        "## Lấy kết quả từ yolov5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZDDEPfxEJqX",
        "outputId": "4f683452-3923-49c0-b15c-20f9dd6c0236"
      },
      "outputs": [],
      "source": [
        "path_source_img = \"/content/drive/MyDrive/xa/code_xa/project3/yolov5/runs/detect/exp10/Copy of BĐ ĐS-MI1112 - GK2020.1-63.jpg\"\n",
        "weight_yolov5 = \"/content/drive/MyDrive/xa/code_xa/project3/yolov5/runs/train/exp21/weights/last.pt\"\n",
        "yolov5_detected =  detect_by_yolov5(weights = weight_yolov5, device = \"cuda\", source = path_source_img )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5l2LpuT6y6p",
        "outputId": "77776ba5-7ab3-48e5-c2e2-2c88f20cefa8"
      },
      "outputs": [],
      "source": [
        "yolov5_detected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Lcqh3Dqtmwc"
      },
      "outputs": [],
      "source": [
        "# path_root_result = \"/content/drive/MyDrive/xa/code_xa/project3/yolov5/runs/detect/exp10/labels\"\n",
        "# result = path_img.split(\"/\")[-1]\n",
        "# path_result = path_root_result + \"/\" + result\n",
        "# path_result = path_result.replace(\".jpg\",\".txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xz2fOJogJ4yr"
      },
      "outputs": [],
      "source": [
        "# with open(path_result,\"r\") as f:\n",
        "#   # print(f.readline())\n",
        "_, x_center, y_center,width, height = [float(x) for x in yolov5_detected[0].split()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39B95v3G6pmk",
        "outputId": "f2f50c54-2aaf-47d2-d591-6ffbdca08dac"
      },
      "outputs": [],
      "source": [
        "print( _, x_center, y_center, width, height)\n",
        "      # x0, y0, x1, y1 = bbox\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ur12AJq0664l",
        "outputId": "52d3fa99-e6d0-4a7a-e2aa-dee443f5344a"
      },
      "outputs": [],
      "source": [
        "print(image_width, image_height)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBQSMqcr9RO6",
        "outputId": "77e4e17e-1882-407b-b6a9-745c0c61c20d"
      },
      "outputs": [],
      "source": [
        "bbox = [ (x_center-width/2)*image_width, (y_center-height/2)*image_height, width*image_width, height*image_height  ]\n",
        "bbox = [int(x) for x in bbox]\n",
        "bbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "dxTNNRr6ljRh",
        "outputId": "e4a394ab-4736-4cc8-dbf4-27740fbbf57f"
      },
      "outputs": [],
      "source": [
        "plot(image_test[  bbox[1]:bbox[1]+bbox[3],  bbox[0]: bbox[0]+bbox[2]  ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XwQdOa1EdEP"
      },
      "outputs": [],
      "source": [
        "#  ###################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sfo45ytBMHG6"
      },
      "outputs": [],
      "source": [
        "# img = cv2.imread('/content/drive/MyDrive/xa/code_xa/project3/Bd_crop.jpg')\n",
        "# img\n",
        "img = image_test[  bbox[1]:bbox[1]+bbox[3],  bbox[0]: bbox[0]+bbox[2]  ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWJAGkAYtBTn",
        "outputId": "7a2d5e94-5456-4eee-dff7-fa699738a3f3"
      },
      "outputs": [],
      "source": [
        "print(bbox[1], bbox[1]+bbox[3],  bbox[0] ,  bbox[0]+bbox[2])\n",
        "#367 2102 103 1614"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOAvboH4ntg-",
        "outputId": "c565041d-7f2a-43f4-e6df-125a3dbc93cb"
      },
      "outputs": [],
      "source": [
        "type(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrqtJI5fxF8M"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "audXaEconwRD"
      },
      "outputs": [],
      "source": [
        "def preprocess(img, factor: int):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    img = Image.fromarray(img)\n",
        "    enhancer = ImageEnhance.Sharpness(img).enhance(factor)\n",
        "    if gray.std() < 30:\n",
        "        enhancer = ImageEnhance.Contrast(enhancer).enhance(factor)\n",
        "    return np.array(enhancer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bnGRkKLKw69_",
        "outputId": "cfbc59eb-8a80-41a3-81e9-f0a35b3b1ad5"
      },
      "outputs": [],
      "source": [
        "# fig, ax = plt.subplots(1, 2, figsize=(24, 8))\n",
        "img_process =  preprocess(img, 30)\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.imshow(img)\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.imshow(img_process)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAylLI4HJ04a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vw4OIndhD2zy"
      },
      "source": [
        "biến đổi thành nhị phân"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "qeB0pvvaw8KN",
        "outputId": "aba092c0-4f97-4eea-f0f2-2f947aa9d1bf"
      },
      "outputs": [],
      "source": [
        "gray_scale=cv2.cvtColor(img_process,cv2.COLOR_BGR2GRAY)\n",
        "th1,img_bin = cv2.threshold(gray_scale,150,225,cv2.THRESH_BINARY)\n",
        "img_bin=~img_bin\n",
        "plot(img_bin)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtv4xzlmHzcj"
      },
      "source": [
        "Applying Morphological Operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gS1bVy2-HqgA"
      },
      "outputs": [],
      "source": [
        "### selecting min size as 15 pixels\n",
        "line_min_width = 15\n",
        "kernal_h = np.ones((1,line_min_width), np.uint8)\n",
        "kernal_v = np.ones((line_min_width,1), np.uint8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSiS1z0sH_1-"
      },
      "source": [
        "Applying Horizontal Kernel on the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jR2IxUZKH50n"
      },
      "outputs": [],
      "source": [
        "img_bin_h = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, kernal_h)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDe03av8Iajl"
      },
      "source": [
        "Applying Vertical Kernel on the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPxaHvpiIbYW",
        "outputId": "7627e171-140d-4c00-a717-178e098214c4"
      },
      "outputs": [],
      "source": [
        "img_bin_v = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, kernal_v)\n",
        "img_bin_v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0xfqPCQIejY"
      },
      "source": [
        "Merging Horizontal and Vertical Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1hfgBjmIgJe"
      },
      "outputs": [],
      "source": [
        "img_bin_final=img_bin_h|img_bin_v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SY7zI5jmIn2n"
      },
      "source": [
        "Now, as you can see from the above image, we can filter most of the text as noise, we do a Connected Component Analysis on the image to get the Bounding Boxes of the checkboxes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRbrHnIbIjVq"
      },
      "outputs": [],
      "source": [
        "_, labels, stats,_ = cv2.connectedComponentsWithStats(~img_bin_final, connectivity= 4, ltype=cv2.CV_32S)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBkC1jCl2L64"
      },
      "source": [
        "`stats`:   \n",
        "```  \n",
        "Combine vertical and horizontal\n",
        "        Args: \n",
        "            bw: black white image\n",
        "        Return:\n",
        "            num_labels: (int) number component after connect '1' element in image\n",
        "            stats: (array-[num_labels, 5]) [left, top, width, height, area] of component\n",
        "            centroids:  (array-[num_labels, 2]) [x, y] centroid of component  \n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEpAVOQXIq4j"
      },
      "outputs": [],
      "source": [
        "for x,y,w,h,area in stats[2:]:\n",
        "    cv2.rectangle(img_process,(x,y),(x+w,y+h),(0,255,0),2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RubAz-2KE-V7"
      },
      "outputs": [],
      "source": [
        "# kernel_len = gray.shape[1]//120\n",
        "# hor_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_len, 1))\n",
        "# image_horizontal = cv2.erode(img_bin, hor_kernel, iterations=3)\n",
        "# horizontal_lines = cv2.dilate(image_horizontal, hor_kernel, iterations=3)\n",
        "\n",
        "# h_lines = cv2.HoughLinesP(\n",
        "#     horizontal_lines, 1, np.pi/180, 30, maxLineGap=250)\n",
        "# plt.figure(figsize=(15,10))\n",
        "# plt.imshow(h_lines)\n",
        "# plt.imshow(h_lines)\n",
        "\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5H7TLY4FhCc"
      },
      "outputs": [],
      "source": [
        "def detect_box(image,line_min_width=15):\n",
        "    \n",
        "    gray_scale=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    th1,img_bin=cv2.threshold(gray_scale,150,230,cv2.THRESH_BINARY)\n",
        "    kernal_h=np.ones((1,line_min_width), np.uint8)\n",
        "    kernal_v=np.ones((line_min_width,1), np.uint8)\n",
        "    img_bin_h=cv2.morphologyEx(~img_bin, cv2.MORPH_OPEN, kernal_h)\n",
        "    img_bin_v=cv2.morphologyEx(~img_bin, cv2.MORPH_OPEN, kernal_v)\n",
        "    \n",
        "    img_bin_final=img_bin_h|img_bin_v\n",
        "    \n",
        "    final_kernel=np.ones((3,3), np.uint8)\n",
        "    img_bin_final=cv2.dilate(img_bin_final,final_kernel,iterations=1)\n",
        "    ret, labels, stats,centroids = cv2.connectedComponentsWithStats(~img_bin_final, connectivity=4, ltype=cv2.CV_32S)\n",
        "    return stats,labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CDziD0cKmme"
      },
      "outputs": [],
      "source": [
        "### lets visualise the connected component image using the function\n",
        "\n",
        "def imshow_components(labels):\n",
        "    ### creating a hsv image, with a unique hue value for each label\n",
        "    label_hue = np.uint8(179*labels/np.max(labels))\n",
        "    ### making saturation and volume to be 255\n",
        "    empty_channel = 255*np.ones_like(label_hue)\n",
        "    labeled_img = cv2.merge([label_hue, empty_channel, empty_channel])\n",
        "    ### converting the hsv image to BGR image\n",
        "    labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_HSV2BGR)\n",
        "    labeled_img[label_hue==0] = 0\n",
        "    ### returning the color image for visualising Connected Componenets\n",
        "    return labeled_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QPmUYPkIKzoe",
        "outputId": "83e716f1-5d16-41f4-f257-2b03b2bb1b38"
      },
      "outputs": [],
      "source": [
        "stats,labels=detect_box(img_process)\n",
        "cc_out=imshow_components(labels)\n",
        "\n",
        "# lưu lại các tọa độ và cho nó vào hình \n",
        "for x,y,w,h,area in stats:\n",
        "    cv2.rectangle(img_process,(x,y),(x+w,y+h),(0,255,0), 1)\n",
        "\n",
        "plot(cc_out)\n",
        "plot(img_process) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3z9a-VGLNZB",
        "outputId": "da50fa58-09cb-4c43-eda4-17d112ce4a32"
      },
      "outputs": [],
      "source": [
        "print(stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnM2kBawo0Vq",
        "outputId": "41648e67-b40d-4c9d-e5cd-e40767615a84"
      },
      "outputs": [],
      "source": [
        "stats.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHHsBYyqnTau",
        "outputId": "e21b7e05-48cd-43a5-8b5b-bab1075cd528"
      },
      "outputs": [],
      "source": [
        "len(stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTqzAI0ZoH_k",
        "outputId": "ba00ac10-2c4f-46f4-9ff9-132ba062536c"
      },
      "outputs": [],
      "source": [
        "stats_word = []\n",
        "stats_hand = []\n",
        "\n",
        "stt_list = []\n",
        "mssv_list = []\n",
        "ho_va_ten_list = []\n",
        "lop_list = []\n",
        "diem_list = []\n",
        "\n",
        "\n",
        "\n",
        "# x y w h\n",
        "for stat in stats :\n",
        "  if  (10 < stat[2]  < 500) and ( 20 < stat[3] < 50):\n",
        "    if (stat[0] < 50) and ( 10 < stat[2] < 100) and  (10 < stat[3] < 80) :\n",
        "      stt_list.append(np.array([stat[0] + 3, stat[1]    , stat[2]-2, stat[3]  ]))\n",
        "      continue\n",
        "    if (20 < stat[0] < 400) and ( 10 < stat[2] < 300) and (10 < stat[3] < 80) :\n",
        "      mssv_list.append(stat)\n",
        "      continue\n",
        "\n",
        "    if ( 150 < stat[0] < 500) and ( 100 < stat[2] < 450) and  (10 < stat[3] < 80) :\n",
        "      ho_va_ten_list.append(stat)\n",
        "      continue\n",
        "\n",
        "    if (150< stat[0] < 700) and ( 100 < stat[2] < 500) and (10 < stat[3] < 80) :\n",
        "      lop_list.append(stat)\n",
        "      continue\n",
        "\n",
        "    if (500 < stat[0] < 1100) and ( 10 < stat[2] < 200) and (stat[3] < 80) :\n",
        "    #   try:\n",
        "    #     diem_list.append(np.array([stat[0], stat[1]  - 10   , stat[2], stat[3]+  20   ]))\n",
        "    #   except:\n",
        "\n",
        "        # try:\n",
        "        #     diem_list.append(np.array([stat[0], stat[1]  - 6   , stat[2], stat[3]+  15   ]))\n",
        "        # except:\n",
        "            try:\n",
        "                diem_list.append(np.array([stat[0], stat[1] - 2 , stat[2], stat[3] + 1]))\n",
        "                \n",
        "            except:\n",
        "                diem_list.append(np.array([stat[0], stat[1], stat[2], stat[3]]))\n",
        "                continue\n",
        "\n",
        "len(stats_word)\n",
        "len(stats_hand)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TljwioiN8C4o",
        "outputId": "8a453c73-0768-44cd-b880-556cfb1509d4"
      },
      "outputs": [],
      "source": [
        "np.array([stats[2][0], stats[2][1], stats[2][2], stats[2][3]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xgrZDFLqGkB"
      },
      "outputs": [],
      "source": [
        "img_draw = img.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofVcAKdCqcbw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuHf9R24FRYQ",
        "outputId": "17c8442c-49dc-4521-8bbf-309fd8a747de"
      },
      "outputs": [],
      "source": [
        "ic(len(stt_list))\n",
        "ic(len(mssv_list))\n",
        "ic(len(ho_va_ten_list))\n",
        "ic(len(lop_list))\n",
        "ic(len(diem_list))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2MYBOsCEN_2"
      },
      "outputs": [],
      "source": [
        "stats_word = []\n",
        "for i in range(len(stt_list)):\n",
        "  stats_word.append(stt_list[i])\n",
        "  stats_word.append(mssv_list[i])\n",
        "  stats_word.append(ho_va_ten_list[i])\n",
        "  stats_word.append(lop_list[i])\n",
        "  stats_word.append(diem_list[i])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "K5BwebB4q_Kx",
        "outputId": "7b5863c0-4b15-4e09-d21d-2a3e58d62e3c"
      },
      "outputs": [],
      "source": [
        "img_crop_list = []\n",
        "for i in  range(len(stats_word)):\n",
        "  crop =  stats_word[i]\n",
        "  img_crop = img[crop[1] : crop[1]+crop[3], crop[0]:crop[2]+crop[0]]\n",
        "  img_crop_list.append(img_crop)\n",
        "# for i in range(len(img_crop_list)):\n",
        "  print(\"##########################___\"+ str(i)+\"________\" + str(crop[0]) + \"___\" + str(crop[1]) + \"___\" + str(crop[2]) + \"___\" + str(crop[3]))\n",
        "  plot(img_crop)\n",
        "  \n",
        "\n",
        "\n",
        "  # plot(img_crop_list[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53wB34W06KiB"
      },
      "outputs": [],
      "source": [
        "# stats_sort"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "wYQwxsJR7BwW",
        "outputId": "f1b9d023-d591-4366-da0a-6ca7ec1bd5a9"
      },
      "outputs": [],
      "source": [
        "plot(img_crop_list[54])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAX5YyZN75kP"
      },
      "source": [
        "**Model**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GY-olEnVDCE"
      },
      "outputs": [],
      "source": [
        "%%capture \n",
        "!pip install craft-text-detector vietocr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jmbPHge7_Q2"
      },
      "outputs": [],
      "source": [
        "from vietocr.tool.predictor import Predictor\n",
        "from vietocr.tool.config import Cfg\n",
        "from craft_text_detector import Craft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvRmnQje5obf",
        "outputId": "2eb71c2b-15e2-4f84-a40d-2f60721c6df5"
      },
      "outputs": [],
      "source": [
        "!scp -r /content/drive/MyDrive/xa/code_xa/project3/weight_mnist/craft_mlt_25k.pth /root/.craft_text_detector/weights/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEDcNoJG8cMU",
        "outputId": "aa1cf7ff-7b58-4ea0-af49-2e2fc3a6dd54"
      },
      "outputs": [],
      "source": [
        "config = Cfg.load_config_from_name('vgg_seq2seq')\n",
        "config['device'] = 'cuda'\n",
        "config['cnn']['pretrained'] = False\n",
        "config['predictor']['beamsearch'] = False\n",
        "\n",
        "craft = Craft(crop_type='box', cuda=True, text_threshold=0.6, \\\n",
        "        link_threshold=0.3, low_text=0.3, long_size=1280)\n",
        "detector = Predictor(config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOJDGIjh8HWe"
      },
      "outputs": [],
      "source": [
        "# img = Image.fromarray(img_box)\n",
        "# pred = detector.predict(img)\n",
        "# # pred = detector.predict(img_box)\n",
        "# pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iRaNy8XBAvc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1r8uElwB8dk"
      },
      "outputs": [],
      "source": [
        "# text_boxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "yNPRb3UNCTME"
      },
      "outputs": [],
      "source": [
        "#@title Default title text\n",
        "def boundingRect(bbox):\n",
        "      bbox = bbox.astype(np.int)\n",
        "      x0, y0 = np.min(bbox, axis=0)\n",
        "      x1, y1 = np.max(bbox, axis=0)\n",
        "      return x0, y0, x1, y1\n",
        "\n",
        "def get_info_word(img_box):\n",
        "  result_of_OCR = \"\"\n",
        "  # img_box = img_crop_list[32]\n",
        "  text_boxes = craft.detect_text(image=img_box)['boxes']\n",
        "  if len(text_boxes) > 0:\n",
        "      text_boxes = [boundingRect(bbox) for bbox in text_boxes]\n",
        "      text_boxes = sorted(text_boxes, key=lambda x: (x[1], x[0]))\n",
        "  s = []\n",
        "  legit_box = []\n",
        "  list_detect = []\n",
        "  dict_of_OCR = {}\n",
        "  dict_of_det = {}\n",
        "  for bbox in text_boxes:\n",
        "      x0, y0, x1, y1 = bbox\n",
        "      if x0 < 0 or y0 < 0:\n",
        "          continue\n",
        "      try:\n",
        "        img = img_box[y0 - 10: y1 + 10, x0  - 6: x1 + 6]\n",
        "        # plot(img)\n",
        "        img = Image.fromarray(img)\n",
        "        \n",
        "      except:\n",
        "        img = img_box[y0: y1, x0: x1]\n",
        "        img = Image.fromarray(img)\n",
        "\n",
        "\n",
        "      list_detect.append(img)\n",
        "      pred = detector.predict(img)\n",
        "      # Draw bbox and name label\n",
        "      # cv2.rectangle(img_box.copy(), (x + x0 - 5, y + y0 - 5), (x + x1 + 5,  y + y1 + 5), (0, 255, 0), 2)\n",
        "      # cv2.putText(img_box.copy(), str(i), (x+x0-5, y+y0-5), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 255), 3)\n",
        "      # plot()\n",
        "      # print(pred)\n",
        "     \n",
        "      if pred:\n",
        "          s.append(pred)\n",
        "          bbox = (x + x0, y + y0, x + x1, y + y1)\n",
        "          dict_of_det[bbox] = pred\n",
        "          \n",
        "          # if 'Tên ' in pred: # mini trick\n",
        "          #     ten_bigbox = stats[i]\n",
        "  if s:\n",
        "      result_of_OCR = \" \".join(s)\n",
        "  return result_of_OCR\n",
        "\n",
        "def get_info_hand(img_box):\n",
        "    result_of_OCR = \"\"\n",
        "    img = Image.fromarray(img_box)\n",
        "    pred = detector.predict(img)\n",
        "    result_of_OCR = pred\n",
        "    return result_of_OCR\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kQSYzHW3zwE"
      },
      "outputs": [],
      "source": [
        "# get_info_word(img)[:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lr_iIDzk0RKT"
      },
      "outputs": [],
      "source": [
        "# for i in range(len(img_crop_list)):\n",
        "#   if i % 5 == 4:\n",
        "#     print(get_info_hand(img_crop_list[i]))\n",
        "#     continue\n",
        "#   print(get_info_word(img_crop_list[i]))\n",
        "  \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8n3JwQO2Tmf",
        "outputId": "58655fe5-7974-4341-a49d-bba022ae8fad"
      },
      "outputs": [],
      "source": [
        "len(img_crop_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOgYKkScno_B"
      },
      "source": [
        "# Thực hiện dự đoán "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6A7GG_PGC4tV"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# df = {\"stt\": [\"0\"], \"mssv\":[\"0\"], \"ho_va_ten\":[\"0\"], \"lop\":[\"0\"], \"diem\":[\"0\"] }\n",
        "# df = pd.DataFrame(df)\n",
        "# for i in range(5, len(img_crop_list), 5):\n",
        "#   # if i > 4 :\n",
        "#     # print(get_info_box(img_crop_list[i]))\n",
        "#     # if i % 5 == 0:\n",
        "#       df_sub = {}\n",
        "#       df_sub[\"stt\"] = [get_info_word(img_crop_list[i])]\n",
        "#     # if i % 5 == 1:\n",
        "#       df_sub[\"mssv\"] = [get_info_word(img_crop_list[i+1])]\n",
        "#     # if i % 5 == 2:\n",
        "#       df_sub[\"ho_va_ten\"] = [get_info_word(img_crop_list[i+2])]\n",
        "#     # if i % 5 == 3:\n",
        "#       df_sub[\"lop\"] = [get_info_word(img_crop_list[i+3])]\n",
        "#     # if i % 5 == 4 :\n",
        "#       # print(get_info_hand(img_crop_list[i]))\n",
        "#       df_sub[\"diem\"] = [get_info_hand(img_crop_list[i+4])]\n",
        "#       df_sub = pd.DataFrame(df_sub)\n",
        "#       df = pd.concat([df,df_sub], ignore_index=True )   \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XigrjCytY4sL"
      },
      "outputs": [],
      "source": [
        "# df = df.drop([0])\n",
        "# df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Omq39qIH9OHC"
      },
      "source": [
        "# Chỉnh nền \n",
        "_________________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZblZwZVBjgI"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install skimage\n",
        "!pip install imutils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcqF0ak9w-I-"
      },
      "outputs": [],
      "source": [
        "def preprocess_xa(img, factor: int):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    img = Image.fromarray(img)\n",
        "    enhancer = ImageEnhance.Sharpness(img).enhance(factor)\n",
        "    if gray.std() < factor:\n",
        "        enhancer = ImageEnhance.Contrast(enhancer).enhance(factor)\n",
        "    return np.array(enhancer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "ARRyFj7w9NrF",
        "outputId": "f08de693-45ac-4ea5-a112-7010a99f5655"
      },
      "outputs": [],
      "source": [
        "img_xa = img_crop_list[134]\n",
        "# img_xa = preprocess_xa(img_xa, 20)\n",
        "plot(img_xa)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuOPg94Rno-3"
      },
      "source": [
        "# Sử dụng CRAFT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fv6__T4rec5V"
      },
      "outputs": [],
      "source": [
        "# get_info_hand(img_xa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NO_Ysxuufn6W",
        "outputId": "c3a320e0-393f-4049-977c-8eca8d4c1fca"
      },
      "outputs": [],
      "source": [
        "def boundingRect(bbox):\n",
        "      bbox = bbox.astype(np.int)\n",
        "      x0, y0 = np.min(bbox, axis=0)\n",
        "      x1, y1 = np.max(bbox, axis=0)\n",
        "      return x0, y0, x1, y1\n",
        "detect_img_list = []\n",
        "img_box = img_xa.copy()\n",
        "result_of_OCR = \"\"\n",
        "# img_box = img_crop_list[32]\n",
        "text_boxes = craft.detect_text(image=img_box)['boxes']\n",
        "if len(text_boxes) > 0:\n",
        "    text_boxes = [boundingRect(bbox) for bbox in text_boxes]\n",
        "    text_boxes = sorted(text_boxes, key=lambda x: (x[3], x[2]))\n",
        "s = []\n",
        "legit_box = []\n",
        "list_detect = []\n",
        "dict_of_OCR = {}\n",
        "dict_of_det = {}\n",
        "for bbox in text_boxes:\n",
        "    x0, y0, x1, y1 = bbox\n",
        "    if x0 < 0 or y0 < 0:\n",
        "        continue\n",
        "    try:\n",
        "        img = img_box[y0 - 6: y1 + 6, x0  - 6: x1 + 6]\n",
        "        detect_img_list.append(img)\n",
        "        plot(img)\n",
        "        img = Image.fromarray(img)\n",
        "    \n",
        "    except:\n",
        "        try:\n",
        "            img = img_box[y0 - 4: y1 + 4, x0  - 4: x1 + 4]\n",
        "            detect_img_list.append(img)\n",
        "            plot(img)\n",
        "            img = Image.fromarray(img)\n",
        "        except:\n",
        "            try:\n",
        "                img = img_box[y0 - 4: y1 + 4, x0  - 4: x1 + 4]\n",
        "                detect_img_list.append(img)\n",
        "                plot(img)\n",
        "                img = Image.fromarray(img)\n",
        "            except:\n",
        "                img = img_box[y0: y1, x0: x1]\n",
        "                detect_img_list.append(img)\n",
        "                plot(img)\n",
        "                img = Image.fromarray(img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giWVsGB7P6mY"
      },
      "outputs": [],
      "source": [
        "# img_check = detect_img_list[0] \n",
        "# img_check = cv2.blur(img_check,(3,3))\n",
        "# img_check = preprocess(img_check, 30)\n",
        "# plot(img_check)\n",
        "# gray_scale=cv2.cvtColor(img_check,cv2.COLOR_BGR2GRAY)\n",
        "# th1,img_bin = cv2.threshold(gray_scale,50,200,cv2.THRESH_BINARY)\n",
        "# img_bin=~img_bin\n",
        "# plot(img_bin)\n",
        "# img_bin = convert2Square(img_bin)\n",
        "# # th1,img_bin = cv2.threshold(img_bin,150,200,cv2.THRESH_BINARY)\n",
        "# plot(img_bin)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__kgs8Et6I--"
      },
      "source": [
        "# CCA và Mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8Gh-xpKQJzL"
      },
      "outputs": [],
      "source": [
        "from skimage.filters import threshold_local\n",
        "from skimage import measure\n",
        "\n",
        "from imutils import perspective\n",
        "import imutils\n",
        "import cv2\n",
        "# from src.data_utils import order_points, convert2Square, draw_labels_and_boxes\n",
        "def convert2Square(image):\n",
        "    \"\"\"\n",
        "    Resize non square image(height != width to square one (height == width)\n",
        "    :param image: input images\n",
        "    :return: numpy array\n",
        "    \"\"\"\n",
        "\n",
        "    img_h = image.shape[0]\n",
        "    img_w = image.shape[1]\n",
        "\n",
        "    # if height > width\n",
        "    if img_h > img_w:\n",
        "        diff = img_h - img_w\n",
        "        if diff % 2 == 0:\n",
        "            x1 = np.zeros(shape=(img_h, diff//2))\n",
        "            x2 = x1\n",
        "        else:\n",
        "            x1 = np.zeros(shape=(img_h, diff//2))\n",
        "            x2 = np.zeros(shape=(img_h, (diff//2) + 1))\n",
        "\n",
        "        squared_image = np.concatenate((x1, image, x2), axis=1)\n",
        "    elif img_w > img_h:\n",
        "        diff = img_w - img_h\n",
        "        if diff % 2 == 0:\n",
        "            x1 = np.zeros(shape=(diff//2, img_w))\n",
        "            x2 = x1\n",
        "        else:\n",
        "            x1 = np.zeros(shape=(diff//2, img_w))\n",
        "            x2 = x1\n",
        "\n",
        "        squared_image = np.concatenate((x1, image, x2), axis=0)\n",
        "    else:\n",
        "        squared_image = image\n",
        "\n",
        "    squared_image = cv2.resize(squared_image, (28, 28))\n",
        "    return squared_image\n",
        "\n",
        "\n",
        "# apply thresh to extracted licences plate\n",
        "\n",
        "def blur(LpRegion):\n",
        "    V = cv2.split(cv2.cvtColor(LpRegion, cv2.COLOR_BGR2HSV))[2]\n",
        "\n",
        "    # adaptive threshold\n",
        "    T = threshold_local(V, 13, offset = 10, method=\"gaussian\")\n",
        "    thresh = (V > T).astype(\"uint8\") * 255\n",
        "\n",
        "    # convert black pixel of digits to white pixel\n",
        "    thresh = cv2.bitwise_not(thresh)\n",
        "    thresh = imutils.resize(thresh, width = 400)\n",
        "    thresh = cv2.medianBlur(thresh, 5)\n",
        "\n",
        "    # connected components analysis\n",
        "    labels =    measure.label(thresh, connectivity=1, background=0)\n",
        "\n",
        "    # plot(labels)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1rim5tc6InJ"
      },
      "outputs": [],
      "source": [
        "def connected_components_analysis(img_check):\n",
        "    img_check = cv2.blur(img_check,(3,3))\n",
        "    img_check = preprocess(img_check, 30)\n",
        "    # plot(img_check)\n",
        "    gray_scale=cv2.cvtColor(img_check,cv2.COLOR_BGR2GRAY)\n",
        "    img_bin=~gray_scale\n",
        "    th1,img_bin = cv2.threshold(img_bin,70,251,cv2.THRESH_BINARY)\n",
        "    # plot(img_bin)\n",
        "    # img_bin = convert2Square(img_bin)\n",
        "    th1,img_bin = cv2.threshold(img_bin,50,240,cv2.THRESH_BINARY)\n",
        "    # plot(img_bin)\n",
        "    # num_labels, labels_im = cv2.connectedComponents(img_bin)\n",
        "    labels_im = measure.label(img_bin, connectivity=2, background=0)\n",
        "    return img_bin, labels_im\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "emOdTp2h6LUf",
        "outputId": "d20922e0-8d21-436a-c508-d6edf03b3cf4"
      },
      "outputs": [],
      "source": [
        "def imshow_components(labels):\n",
        "    # Map component labels to hue val\n",
        "    label_hue = np.uint8(179*labels/np.max(labels))\n",
        "    blank_ch = 255*np.ones_like(label_hue)\n",
        "    labeled_img = cv2.merge([label_hue, blank_ch, blank_ch])\n",
        "\n",
        "    # cvt to BGR for display\n",
        "    labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_HSV2BGR)\n",
        "\n",
        "    # set bg label to black\n",
        "    labeled_img[label_hue==0] = 0\n",
        "\n",
        "    plot(labeled_img)\n",
        "img_bin, labels_im = connected_components_analysis(img_xa)\n",
        "imshow_components(labels_im)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdrAuI7v9CFq"
      },
      "outputs": [],
      "source": [
        "def get_candidates_img(img_bin, labels_im ):\n",
        "    candidate_list = []\n",
        "    for label in np.unique(labels_im):\n",
        "        # if this is background label, ignore it\n",
        "        if label == 0:\n",
        "            continue\n",
        "\n",
        "        # init mask to store the location of the character candidates\n",
        "        mask = np.zeros(img_bin.shape, dtype=\"uint8\")\n",
        "        mask[labels_im == label] = 255\n",
        "\n",
        "        # find contours from mask\n",
        "        contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        if len(contours) > 0:\n",
        "            contour = max(contours, key=cv2.contourArea)\n",
        "            (x, y, w, h) = cv2.boundingRect(contour)\n",
        "\n",
        "            # rule to determine characters\n",
        "            aspectRatio = w / float(h)\n",
        "            solidity = cv2.contourArea(contour) / float(w * h)\n",
        "            heightRatio = h / float(labels_im.shape[0])\n",
        "\n",
        "            if  solidity > 0.1 and 0.35 < heightRatio < 2.0:\n",
        "            # if True:\n",
        "\n",
        "                # extract characters\n",
        "                candidate = np.array(mask[y:y + h, x:x + w])\n",
        "                # plot(candidate)\n",
        "                square_candidate = convert2Square(candidate)\n",
        "\n",
        "                plot(square_candidate)\n",
        "                \n",
        "                candidate_list.append((square_candidate, x))\n",
        "\n",
        "            # square_candidate = cv2.resize(square_candidate, (28, 28), cv2.INTER_AREA)\n",
        "            # square_candidate = square_candidate.reshape((28, 28, 1))\n",
        "            \n",
        "    return candidate_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTNFILXOEbK9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIY4wfse6L-D"
      },
      "source": [
        "# Mô hình dự đoán :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnBF4HpiYaOQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # feature extractor\n",
        "        self.activation = nn.Tanh()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1)\n",
        "        self.avgpool = nn.AvgPool2d(kernel_size=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1)\n",
        "        self.dropout1 = nn.Dropout(0.3)\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "        # classifer\n",
        "        self.fc1 = nn.Linear(16*4*4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # feature extraction\n",
        "        x = self.activation(self.conv1(x))\n",
        "        x = self.avgpool(x)\n",
        "        \n",
        "        x = self.activation(self.conv2(x))\n",
        "        x = self.avgpool(x)\n",
        "        \n",
        "        x = self.dropout1(x)\n",
        "        \n",
        "        # classification\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.activation(self.fc1(x))\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = self.activation(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "        \n",
        "        x = self.softmax(self.fc3(x))\n",
        "        return x\n",
        "model = Net()\n",
        "model= torch.load(\"/content/drive/MyDrive/xa/code_xa/project3/weight_mnist/model_mnist_xa_drop.pt\").cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MF59SQHybBZI"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "def predict_score(candidates):\n",
        "    pred_list = []\n",
        "    result = 1000\n",
        "    candidates = sorted(candidates, key = lambda x: x[1])\n",
        "    transform = transforms.Compose([\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,))\n",
        "                                    \n",
        "                                     ])\n",
        "    for square_candidate, x in candidates:\n",
        "        x  = square_candidate\n",
        "        # ic(x)\n",
        "        import scipy\n",
        "        x = scipy.pad(array= x , pad_width=[5, 5], mode='constant', constant_values=0)\n",
        "        x = cv2.resize(x, (28, 28))\n",
        "        # plot(x)\n",
        "        x = transform(x)\n",
        "\n",
        "        # x = torch.tensor(x)\n",
        "        x = torch.unsqueeze(x, dim=0 )\n",
        "        # x = torch.unsqueeze(x, dim=0)\n",
        "        x = x.type(torch.cuda.FloatTensor)\n",
        "\n",
        "\n",
        "        x = x.cuda()\n",
        "        pred =  model(x)\n",
        "        # print(\"Dự đoán:\")\n",
        "        # print(pred)\n",
        "        # ic(\"AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\")\n",
        "        # print(torch.argmax(pred, dim=-1).cpu().detach().numpy())\n",
        "        if pred.cpu().detach().numpy().max() > 0.55 :\n",
        "            pred = str(torch.argmax(pred, dim=-1).cpu().detach().numpy()[0])\n",
        "            pred_list.append(pred)\n",
        "\n",
        "    try:\n",
        "        result = (float(pred_list[0])*10 + float(pred_list[-1]))*1.0/10\n",
        "    except:\n",
        "        pass\n",
        "    return \"{:.1f}\".format(result) \n",
        "\n",
        "# predict_score(candidate_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpeMOXel7PSZ"
      },
      "outputs": [],
      "source": [
        "def get_info_score(img_xa):\n",
        "    img_bin, labels_im = connected_components_analysis(img_xa)\n",
        "    candidate_list =  get_candidates_img(img_bin, labels_im )\n",
        "     \n",
        "    return predict_score(candidate_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OdAy1Hj_Fyli",
        "outputId": "1da0ba93-10e7-434c-ceb1-28dcb4688ae9"
      },
      "outputs": [],
      "source": [
        "get_info_score(img_crop_list[34])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PZaKWSDKFm1"
      },
      "source": [
        "# MAIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GAmJ4GAxKHJ3",
        "outputId": "d196fc3b-50b5-4502-e891-5d0faca231e3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "df = {\"stt\": [\"0\"], \"mssv\":[\"0\"], \"ho_va_ten\":[\"0\"], \"lop\":[\"0\"], \"diem\":[\"0\"] }\n",
        "df = pd.DataFrame(df)\n",
        "for i in range(5, len(img_crop_list), 5):\n",
        "  # if i > 4 :\n",
        "    # print(get_info_box(img_crop_list[i]))\n",
        "    # if i % 5 == 0:\n",
        "      df_sub = {}\n",
        "      df_sub[\"stt\"] = [get_info_word(img_crop_list[i])]\n",
        "    # if i % 5 == 1:\n",
        "      df_sub[\"mssv\"] = [get_info_word(img_crop_list[i+1])]\n",
        "    # if i % 5 == 2:\n",
        "      df_sub[\"ho_va_ten\"] = [get_info_word(img_crop_list[i+2])]\n",
        "    # if i % 5 == 3:\n",
        "      df_sub[\"lop\"] = [get_info_word(img_crop_list[i+3])]\n",
        "    # if i % 5 == 4 :\n",
        "      # print(get_info_hand(img_crop_list[i]))\n",
        "      df_sub[\"diem\"] = [get_info_score(img_crop_list[i+4])]\n",
        "      df_sub = pd.DataFrame(df_sub)\n",
        "      df = pd.concat([df,df_sub], ignore_index=True )   \n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "L2tC2tdMKsrt",
        "outputId": "09a6c8f8-807f-4c1f-ae5d-ac853b864fe0"
      },
      "outputs": [],
      "source": [
        "for i in range(len(img_crop_list)):\n",
        "    if i % 5 == 4 :\n",
        "        print(\"--------------{i}-------------------------------\".format(i = i))\n",
        "        plot(img_crop_list[i])\n",
        "        print(\"AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMPf87ghPtfx"
      },
      "outputs": [],
      "source": [
        "df1 = df.drop([0])\n",
        "df1.to_excel(\"/content/drive/MyDrive/xa/code_xa/project3/project3_data/qt2022.xlsx\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrBoPHTEsrdQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "project3_main_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
